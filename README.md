# ollama-open-webui
Dockerized Open-WebUI Ollama setup to run two (and more) models simultaneously
